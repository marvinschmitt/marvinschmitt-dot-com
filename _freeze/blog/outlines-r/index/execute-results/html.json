{
  "hash": "a34be62cd29e6d94a984fa87650e4154",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using LLMs with Structured Generation with Outlines in R\"\ndescription: \"A short proof-of-concept that calls the Outlines package from within R, with OpenAI's GPT-4o as a language model.\"\ndate: 10-15-2024\ncategories: \n  - tech\n  - programming\ndraft: false\nnumber-sections: false\nimage: outlines-r-thumbnail.png\nformat:\n  html:\n    fig-cap-location: bottom\n    include-before-body: ../../html/margin_image.html\n    include-after-body: ../../html/blog_footer.html\n    comments: false\neditor: \n  markdown: \n    wrap: sentence\n---\n\n\nPython is a great Swiss knife for many tasks, especially when it comes to deep learning these days.\nHowever, many statisticians and data scientists prefer working in R \nIn this short blog post, we'll use the `reticulate` package to work with Python code inside R, demonstrating this with the `outlines` package and OpenAI's GPT-4o language model.\n\n## Load Reticulate and Set Up the Environment\n\nLoad the `reticulate` library to interface between R and Python, and specify the conda environment that contains the necessary Python packages (`outlines`, `openai` and `tiktoken` in my case).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'reticulate' was built under R version 4.4.1\n```\n\n\n:::\n\n```{.r .cell-code}\nuse_condaenv(\"/Users/marvin/miniforge3/envs/outlines_py310\", required = TRUE)\nos <- import(\"os\")\noutlines <- import(\"outlines\")\n```\n:::\n\n\n## Set Up the OpenAI Model\n\nSet up the OpenAI model using the `outlines` package. \nYou should not write your API key directly in the code.\nInstead, we use an environment variable which we set in the terminal before running the R script.\nThis ensures that you don't accidentally leak your secret API key.\n\n\n::: {.cell}\n\n```{.r .cell-code}\napi_key <- Sys.getenv(\"OPENAI_API_KEY\")\nmodel <- outlines$models$openai(\"gpt-4o\", api_key = api_key)\n```\n:::\n\n\n## Generate a Response\n\nNow we'll use the language model to answer a question, and restrict the answer to a choice from multiple options.\nFor demonstration purposes, let's see whether GPT-4 can answer a basic question about Bayesian statistics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchoices = c(\"Prior\", \"Likelihood\", \"Marginal Likelihood\", \"Evidence\", \"Posterior\")\ngenerator <- outlines$generate$choice(model, choices)\n\nresult <- generator(\"In a Bayesian model, what do we call the probability distribution of parameters given the data?\")\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Posterior\"\n```\n\n\n:::\n:::\n\n\nLet's try another more technical question, this time about the choice of a suitable likelihood for count data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchoices = c(\"Gaussian\", \"Poisson\", \"Negative-Binomial\", \"Gamma\")\ngenerator <- outlines$generate$choice(model, choices)\n\nresult <- generator(\"We have a Bayesian model for count data $y$. The data $y$ is lower-bounded at zero, can take on integer values, and is probably overdispersed. The most suitable likelihood is \")\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Negative-Binomial\"\n```\n\n\n:::\n:::\n\n\n\n## Next Steps\n\nIn this demonstrator, we used `reticulate` as a simple bridge to call Python packages from within R.\nAs a next steps, you can try other generation schemes (not just multiple choice) or build more complex pipelines.\nAlso, Outlines really shines if you use it with a local open source LLM, so you should try that as well.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}